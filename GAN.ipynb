{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMb/f+rGqhuBXlcOhr5IbsR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/efitzgerald763/snRNAseq_ssGSEA_DE/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyYIkcNa7EJ2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, z):\n",
        "        x_encoded = self.encoder(x)\n",
        "        combined = x_encoded * z\n",
        "        return self.decoder(combined)\n",
        "\n",
        "# Define the discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Define the inverse mapping function (mapping disease data to latent space)\n",
        "class InverseFunction(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(InverseFunction, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, latent_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Adversarial loss\n",
        "adversarial_loss = nn.BCELoss()\n",
        "\n",
        "# Instantiate the models\n",
        "input_dim = 15000  # Adjust based on gene expression data\n",
        "latent_dim = 10    # Number of patterns\n",
        "output_dim = input_dim\n",
        "batch_size = 32\n",
        "\n",
        "# Create instances of the models\n",
        "generator = Generator(input_dim, latent_dim, output_dim)\n",
        "discriminator = Discriminator(output_dim)\n",
        "inverse_function = InverseFunction(output_dim, latent_dim)\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "optimizer_I = optim.Adam(inverse_function.parameters(), lr=0.0002)\n",
        "\n",
        "# Training loop (simplified version)\n",
        "for epoch in range(10000):\n",
        "    # Sample real control data x and latent variable z\n",
        "    x_real = torch.randn(batch_size, input_dim)\n",
        "    z = torch.rand(batch_size, latent_dim)\n",
        "\n",
        "    # Generate synthesized disease data\n",
        "    y_synth = generator(x_real, z)\n",
        "\n",
        "    # Discriminator training\n",
        "    optimizer_D.zero_grad()\n",
        "    real_loss = adversarial_loss(discriminator(x_real), torch.ones(batch_size, 1))\n",
        "    fake_loss = adversarial_loss(discriminator(y_synth.detach()), torch.zeros(batch_size, 1))\n",
        "    d_loss = real_loss + fake_loss\n",
        "    d_loss.backward()\n",
        "    optimizer_D.step()\n",
        "\n",
        "    # Generator and inverse function training\n",
        "    optimizer_G.zero_grad()\n",
        "    optimizer_I.zero_grad()\n",
        "    g_loss = adversarial_loss(discriminator(y_synth), torch.ones(batch_size, 1))\n",
        "    reconstruction_loss = nn.MSELoss()(inverse_function(y_synth), z)\n",
        "    total_loss = g_loss + reconstruction_loss\n",
        "    total_loss.backward()\n",
        "    optimizer_G.step()\n",
        "    optimizer_I.step()\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch} | D Loss: {d_loss.item()} | G Loss: {g_loss.item()} | Reconstruction Loss: {reconstruction_loss.item()}\")\n",
        "\n",
        "print(\"Training complete.\")\n"
      ]
    }
  ]
}